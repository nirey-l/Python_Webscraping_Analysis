{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d1b63e3",
   "metadata": {},
   "source": [
    "### 1. Daum 뉴스 기사 제목 스크래핑하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90268913",
   "metadata": {},
   "source": [
    "질문1. 아래의 url에서 뉴스 기사의 링크와 제목을 출력하시오\n",
    "*  경제 뉴스 url = 'https://news.daum.net/economy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73cd7dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://news.daum.net/economy\n",
      "<class 'requests.models.Response'>\n",
      "200\n",
      "<class 'bs4.element.ResultSet'> 9\n",
      "https://v.daum.net/v/20260206210724599 '美 정부 안전망 없다' 충격…비트코인 6만달러선까지 후퇴·이더리움도 동반 흔들 [이수현의 코인레이더] <이수현의 코인레이더>는 한 주간 가상자산(암호화폐) 시장의 흐름을 짚고, 그 배경을 해설하는 코너입니다. 단순한 시세 나열을 넘어 글로벌 경제 이슈와 투자자 움직임을 입체적으로 분석하며, 시장의 방향성을 가늠할 수 있는 인사이트를 제공합니다. 주요 코인 1. 비트코인(BTC) 이번 주 비트코인은 브레이크 없는 하락세를 보이면서 결국 6만달러선까지 하락 한국경제 7분 전\n",
      "https://v.daum.net/v/20260206202727940 정책자금 브로커 구조 손본다…중기부, 서류 간소화도 추진 KBS 47분 전\n",
      "https://v.daum.net/v/20260206185614120 휴머노이드 상용화 ‘초읽기’…“안전성·신뢰성이 최우선” 한겨레 2시간 전\n",
      "https://v.daum.net/v/20260206184326845 EV 부진에 배터리서 발 빼는 美 완성차… LG에너지솔루션, 스텔란티스 합작법인 인수 동아일보 3시간 전\n",
      "https://v.daum.net/v/20260206172807685 키키도 소환한 그 감성⋯Y2K, 왜 아직도 먹히냐면요 [솔드아웃] 이투데이 4시간 전\n",
      "https://v.daum.net/v/20260206162540251 2026 지금은 크립토 윈터인가? 규제 이후 시장의 변화 [타이거리서치 리포트] 한국경제 5시간 전\n",
      "https://v.daum.net/v/20260206160226448 1년새 2900% '폭풍 성장'…\"주식 토큰화, '코스닥 3000' 만들 성장동력\" 한국경제 5시간 전\n",
      "https://v.daum.net/v/20260206153503273 새벽은 풀고, 일요일 묶어버리면… 대형마트 새벽배송 논의, 지표가 먼저 보여준 결과 JIBS 6시간 전\n",
      "https://v.daum.net/v/20260206152943998 [단독] '17만' 군인 노후자금 녹는다…3700억 지원 '논란 폭발' 한국경제 6시간 전\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# dict 타입으로 요청 파라미터 설정\n",
    "# 요청 파라미터 설정: 고정된 주소 뒤에 내가 원하는 조건(카테고리 등)을 유동적으로 조립하기 위해 미리 값을 준비해두는 과정\n",
    "req_param = {\n",
    "    'category': 'economy' \n",
    "}\n",
    "\n",
    "url = 'https://news.daum.net/{category}'.format(**req_param)\n",
    "print(url) \n",
    "\n",
    "# 요청 헤더 설정 why? 프로그램이 아닌 사람처럼 보이게 하기 위함\n",
    "# 개발자 도구 네트워크 Doc의 헤더에서 가져올 수 있음\n",
    "req_header = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/144.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# requests의 get() 함수 호출하기\n",
    "# requests.get(): 이 주소(URL)에 있는 정보를 나에게 보내달라고 요청 하는 역할\n",
    "# url: \"어디로\" 갈 것인가? e.g. 다음 경제 뉴스 페이지\n",
    "# headers=req_header: \"어떤 모습으로\" 갈 것인가? 앞서 설명한 것처럼 user-agent를 담아 사람인 척 위장하는 가면을 쓰는 부분\n",
    "res = requests.get(url, headers=req_header)\n",
    "\n",
    "print(type(res)) \n",
    "print(res.status_code) \n",
    "\n",
    "# 서버에서 제공한 실제 인코딩 방식으로 강제 설정 (한글 깨짐 방지)\n",
    "res.encoding = res.apparent_encoding\n",
    "\n",
    "# if res.ok: 서버로부터 응답을 제대로 받았는지\n",
    "if res.ok:\n",
    "    # res.text는 긴 글자 뭉친인데 BeautifulSoup을 거치면 '태그를 찾아줘' 등과 같은 명령어를 쓸 수 있는 soup 객체가 됨\n",
    "    # html.parser: BeautifulSoup에게 html.parser 도구로 분석하라고 알려줌\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    \n",
    "    # type: 데이터 형식\n",
    "    # len: 그 안에 든 뉴스 기사가 몇 개인지\n",
    "    print(type(ul_tags), len(ul_tags)) \n",
    "\n",
    "    # 긴 html에서 내가 원하는 부분만 가져오기\n",
    "    # ul.list_newsheadline2: 클래스가 list_newsheadline2인 ul 태그 찾기\n",
    "    # a.item_newsheadline2: 클래스가 item_newsheadline2인 a 태그들만 찾기\n",
    "    ul_tags = soup.select(\"ul.list_newsheadline2 a.item_newsheadline2\")\n",
    "\n",
    "    # 찾아온 뉴스 꾸러미(ul_tags)에서 기사를 하나씩 꺼내서(ul_tag) 아래 작업을 반복\n",
    "    for ul_tag in ul_tags:\n",
    "\n",
    "        # <ul>...</ul> 태그 사이에 적힌 글자(뉴스 제목)만 가져오기\n",
    "        # .text: 태그 안의 텍스트만 가져오기\n",
    "        # .strip(): 공백, 줄바꿈 제거\n",
    "        title = ul_tag.text.strip() \n",
    "\n",
    "        # 해당하는 링크 가져오기\n",
    "        link = ul_tag['href']\n",
    "\n",
    "        print(link, title)\n",
    "\n",
    "else:\n",
    "    # 응답(response)이 Error이면 status code 출력\n",
    "    print(f'Error Code = {res.status_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ecd751",
   "metadata": {},
   "source": [
    "질문2. 여러개의 section 중 하나를 선택해서 url에서 뉴스기사의 링크와 제목을 출력하는 코드를 함수로 작성하기\n",
    "*   경제 뉴스 url = 'https://news.daum.net/economy'\n",
    "*   사회 뉴스 url = 'https://news.daum.net/society'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1673e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "section_dict = {'기후/환경':'climate','사회':'society','경제':'economy','정치':'politics', '국제':'world','문화':'culture',\n",
    "                '생활':'life','IT/과학':'tech','인물':'people','지식/칼럼':'understanding','연재':'series'}\n",
    "\n",
    "def print_news(section_name):\n",
    "    # 정치: section_dict에 없을 때를 대비한 기본값  \n",
    "    sid = section_dict.get(section_name, '정치')\n",
    "    url = f'https://news.daum.net/{sid}'\n",
    "    # f-string: 문자열 안에서 중괄호 { }를 사용해 변수나 계산식을 직접 넣을 수 있음\n",
    "    # print(\"======>\" + url + section_name + \"뉴스\" + \"<======\")\n",
    "    print(f'======> {url} {section_name} 뉴스 <======')\n",
    "\n",
    "    # 요청 헤더 설정\n",
    "    req_header = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/144.0.0.0 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    # requests의 get() 함수 호출하기\n",
    "    # requests.get(): 이 주소(URL)에 있는 정보를 나에게 보내달라고 요청 하는 역할\n",
    "    # url: \"어디로\" 갈 것인가? e.g. 다음 경제 뉴스 페이지\n",
    "    # headers=req_header: \"어떤 모습으로\" 갈 것인가? 앞서 설명한 것처럼 user-agent를 담아 사람인 척 위장하는 가면을 쓰는 부분\n",
    "    res = requests.get(url, headers=req_header)\n",
    "\n",
    "    # 서버에서 제공한 실제 인코딩 방식으로 강제 설정 (한글 깨짐 방지)\n",
    "    res.encoding = res.apparent_encoding\n",
    "    \n",
    "    # if res.ok: 서버로부터 응답을 제대로 받았는지\n",
    "    if res.ok:\n",
    "        # res.text는 긴 글자 뭉친인데 BeautifulSoup을 거치면 '태그를 찾아줘' 등과 같은 명령어를 쓸 수 있는 soup 객체가 됨\n",
    "        # html.parser: BeautifulSoup에게 html.parser 도구로 분석하라고 알려줌\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "        # 긴 html에서 내가 원하는 부분만 가져오기\n",
    "        # ul.list_newsheadline2: 클래스가 list_newsheadline2인 ul 태그 찾기\n",
    "        # a.item_newsheadline2: 클래스가 item_newsheadline2인 a 태그들만 찾기\n",
    "        ul_tags = soup.select(\"ul.list_newsheadline2 a.item_newsheadline2\")\n",
    "\n",
    "        # 찾아온 뉴스 꾸러미(ul_tags)에서 기사를 하나씩 꺼내서(ul_tag) 아래 작업을 반복\n",
    "        for ul_tag in ul_tags:\n",
    "\n",
    "            # <ul>...</ul> 태그 사이에 적힌 글자(뉴스 제목)만 가져오기\n",
    "            # .text: 태그 안의 텍스트만 가져오기\n",
    "            # .strip(): 공백, 줄바꿈 제거\n",
    "            title = ul_tag.text.strip() \n",
    "\n",
    "            # 해당하는 링크 가져오기\n",
    "            link = ul_tag['href']\n",
    "\n",
    "            print(link, title)\n",
    "\n",
    "    else:\n",
    "            # 응답(response)이 Error이면 status code 출력\n",
    "            print(f'Error Code = {res.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee9d9469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======> https://news.daum.net/economy 경제 뉴스 <======\n",
      "https://v.daum.net/v/20260206202727940 정책자금 브로커 구조 손본다…중기부, 서류 간소화도 추진 정부가 중소기업·소상공인 정책자금 신청 과정에서 브로커의 개입을 막기 위해 정책자금 신청 때 제출 서류를 간소화하는 등 제도 개편에 나서기로 했습니다. 중소벤처기업부는 오늘(6일) 영등포구 중소기업중앙회에서 노용석 제1차관 주재로 중소벤처기업진흥공단, 소상공인시장진흥공단, 기술보증기금, 신용보증재단중앙회, 중소기업기술정보진흥원, 창업진흥원 등이 참여한 KBS 23분 전\n",
      "https://v.daum.net/v/20260206185614120 휴머노이드 상용화 ‘초읽기’…“안전성·신뢰성이 최우선” 한겨레 2시간 전\n",
      "https://v.daum.net/v/20260206184326845 EV 부진에 배터리서 발 빼는 美 완성차… LG에너지솔루션, 스텔란티스 합작법인 인수 동아일보 2시간 전\n",
      "https://v.daum.net/v/20260206172807685 키키도 소환한 그 감성⋯Y2K, 왜 아직도 먹히냐면요 [솔드아웃] 이투데이 3시간 전\n",
      "https://v.daum.net/v/20260206162540251 2026 지금은 크립토 윈터인가? 규제 이후 시장의 변화 [타이거리서치 리포트] 한국경제 4시간 전\n",
      "https://v.daum.net/v/20260206160226448 1년새 2900% '폭풍 성장'…\"주식 토큰화, '코스닥 3000' 만들 성장동력\" 한국경제 5시간 전\n",
      "https://v.daum.net/v/20260206153503273 새벽은 풀고, 일요일 묶어버리면… 대형마트 새벽배송 논의, 지표가 먼저 보여준 결과 JIBS 5시간 전\n",
      "https://v.daum.net/v/20260206152943998 [단독] '17만' 군인 노후자금 녹는다…3700억 지원 '논란 폭발' 한국경제 5시간 전\n",
      "https://v.daum.net/v/20260206143213520 [연합뉴스 이 시각 헤드라인] - 14:30 연합뉴스 6시간 전\n",
      "======> https://news.daum.net/society 사회 뉴스 <======\n",
      "https://v.daum.net/v/20260206204236152 \"2037년 부족 의사 4262~4800명\"...내년도 의대 정원, 10일 결정 [유창재 기자] ▲  정은경 보건복지부 장관이 6일 오후 서울 서초구 국제전자센터에서 열린 제6차 보건의료정책심의위원회에서 발언하고 있다.ⓒ 보건복지부정부가 2037년 부족한 의사 인력 규모를 약 4262명에서 4800명으로 정했다. 내년도 의과대학 정원 증원 규모는 다음주 10일, 추가 논의를 거쳐 최종 결정하기로 했다. 반면 의료계는 집단 반발을 예고했 오마이뉴스 8분 전\n",
      "https://v.daum.net/v/20260206190244321 동영상     3월 '학생맞춤통합지원' 시행…학교 준비 상황은? EBS 2시간 전\n",
      "https://v.daum.net/v/20260206185525102 [단독] 외국인이어서… 경제적 부담에… 3년간 400여명 ‘버려진 죽음’ 국민일보 2시간 전\n",
      "https://v.daum.net/v/20260206185230030 동영상     [DM왔어요] 불길 치솟은 '4중 추돌'…지체 없이 나간 시민과 경찰 外 연합뉴스TV 2시간 전\n",
      "https://v.daum.net/v/20260206181622201 조선업 이주노동자 3년 새 5배 증가, 처우는 ‘나 몰라라’ 매일노동뉴스 3시간 전\n",
      "https://v.daum.net/v/20260206180018721 “임금체불 막고 노후소득 강화”…사업장 규모·적용시기는 빠져 서울경제 3시간 전\n",
      "https://v.daum.net/v/20260206175015398 장윤영 신임 김천지청장 취임...\"보완수사권 있을 때 더 듣고 확인해야... 본연의 임무 강조\" 법률신문 3시간 전\n",
      "https://v.daum.net/v/20260206170628940 동영상     [사사건건] 이 주의 사람…군식대첩 우승‘강수’팀 KBS 4시간 전\n",
      "https://v.daum.net/v/20260206165724565 공소기각에 환히 웃은 곽상도 \"내가 피해자, 그만 좀 괴롭혀라\" 오마이뉴스 4시간 전\n"
     ]
    }
   ],
   "source": [
    "print_news('경제')\n",
    "print_news('사회')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0fc1fc",
   "metadata": {},
   "source": [
    "### 2-1. Nate 뉴스 기사 제목 스크래핑하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500e813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ade47db3",
   "metadata": {},
   "source": [
    "### 2-2. 하나의 네이버 웹툰과 1개의 회차에 대한 Image 다운로드 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e799d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "318fe264",
   "metadata": {},
   "source": [
    "### 2-3. 하나의 네이버 웹툰과 여러개의 회차에 대한 Image 다운로드 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8da8c04",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
